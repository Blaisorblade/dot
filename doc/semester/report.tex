\documentclass[preprint]{sigplanconf}

\input{dot_macros}

    \usepackage[pdftex,
                hyperindex,
                plainpages=false,
                breaklinks,
                colorlinks,
                citecolor=black,
                filecolor=black,
                linkcolor=black,
                pagecolor=black,
                urlcolor=black]{hyperref}
    \usepackage[pdftex]{graphicx}
    \DeclareGraphicsExtensions{.jpg,.pdf}
    \pdfcatalog {
        /PageMode (/UseNone)
    }
    \usepackage{thumbpdf}
    \usepackage[pdftex]{color}

\begin{document}

\conferenceinfo{EDIC}{July 2012, EPFL.}
\copyrightyear{2012}
\copyrightdata{[to be supplied]}

\titlebanner{Dependent Object Types}                           % These are ignored unless
\preprintfooter{Spring 2012 Semester Project -- Nada Amin}     % 'preprint' option specified.

\title{Dependent Object Types}
\subtitle{Spring 2012 Semester Project}

\authorinfo{Nada Amin}
           {EPFL}
           {nada.amin@epfl.ch}

\maketitle

\begin{abstract}
In my semester project, I have studied a new proposed type-theoretic
foundation of Scala and languages like it: the Dependent Object Types
calculus (DOT). DOT models Scala's path-dependent types and abstract
type members, as well as its mixture of nominal and structural typing
through the use of refinement types. My ultimate goal was to prove DOT
sound, but instead, I found lots of counterexamples to soundness, and
have explored patches to the calculus.
\end{abstract}


\section{Introduction}

We briefly summarize the salient features of the original DOT
calculus. The reader is encouraged to consult the appendices for the
full description. We will often refer to the rules of the calculus
in the remainder of this report.

DOT models Scala's path-dependent types and abstract type members, as
well as its mixture of nominal and structural typing through the use
of refinement types. It makes no attempt to model inheritance or
mixing composition. The calculus does not model what's currently in
Scala: it is more normative than descriptive.

The terms in DOT consists of variables $x$, $y$, $z$, lambda
abstractions $\abs x T t$, function applications $\app t {t'}$, field
selections $t.l$ and object creation expressions $\new x c t$, where
$c$ is a constructor $T_c \ldefs{\seq{l = v}}$.

The types in DOT consists of type selections $p.L$, refinement types
$T \refine z {\seq{D}}$, function types $T \tfun T'$, type intersections
$T \tand T'$, type unions $T \tor T'$, a top type $\Top$, and a bottom
type $\Bot$.

The DOT calculus is expressed using a small-step operational
semantics. The typing judgment directly or indirectly uses the
following other judgments: membership, expansion, well-formedness and
subtyping. Expansion ``flattens'' all the declarations of a type, and
membership selects a particular flattened declaration by
label. Expansion is precise. The \textsc{new} typing judgment relies
on the preciseness of expansion to check that all bounds of types
declared within the type of the constructor are consistent (i.e. that
the lower bound is a subtype of the upper bound), and that all values
declared within the type of the constructor are initialized.

In the rest of this introduction, we present some program examples. We
summarize our findings of counterexamples to soundness in
section~\ref{counterexs}. We explore some patches to the calculus in
section~\ref{patches}. We discuss opportunities for future work and
conclude in section~\ref{conclusion}.

\subsection{Program Examples}

\subsubsection{Basics: Booleans, Error, \ldots}
This program defines a $\mi{root}$ object with basic types
($\mi{Unit}$, $\mi{Boolean}$, $\mi{Nat}$) and values ($\mi{true}$,
$\mi{false}$, $\mi{error}$, $\mi{zero}$). For brevity, I've omitted
the code related to natural numbers. During the object creation, the
value labels such as $\mi{false}$ are all initialized.

\begin{align*}
&\mlnew {\mi{root}} {\Top \mlrefine r {\\\displaybreak[3]
&\ \Ldecl {\mi{Unit}} \Bot \Top\\
&\ \ldecl {\mi{unit}} {\Top \tfun {r.\mi{Unit}}}\\
&\ \Ldecl {\mi{Boolean}} \Bot {\Top \mlrefine z {\\
&\ \gap \ldecl {\mi{ifNat}} {(r.\mi{Unit} \tfun r.\mi{Nat}) \tfun (r.\mi{Unit} \tfun r.\mi{Nat}) \tfun r.\mi{Nat}}\\
&\gap}}\\
&\ \ldecl {\mi{false}} {{r.\mi{Unit}} \tfun {r.\mi{Boolean}}}\\
&\ \ldecl {\mi{true}} {{r.\mi{Unit}} \tfun {r.\mi{Boolean}}}\\
&\ \ldots\\\displaybreak[3]
&\ \ldecl {\mi{error}} {{r.\mi{Unit}} \tfun \Bot}\\
&}\mlldefs{\\\displaybreak[3]
&\ \mi{unit}  = \abs x \Top {\new u {\mi{root}.\mi{Unit}} u}\\
%
&\ \mi{false} = \abs u {\mi{root}.\mi{Unit}} {\\
&\ \gap \mlnew {\mi{ff}} {\mi{root}.\mi{Boolean} \mlldefs{\\\displaybreak[3]
&\ \gap\gap {\mi{ifNat}} = \abs t {\mi{root}.\mi{Unit} \tfun \mi{root}.\mi{Nat}} {\\&\gap\gap\gap\abs e {\mi{root}.\mi{Unit} \tfun \mi{root}.\mi{Nat}}\\&\gap\gap\gap\app e {\mi{root}.\mi{unit}}}\\
&\ \gap}}{
\ \gap \mi{ff}}
&}\\
%
&\ \mi{true} = \ldots\\
%
&\ \mi{error} = \abs u {\mi{root}.\mi{Unit}} {\app {\mi{root}.\mi{error}} u}\\
&\ \ldots\\
&}}{
\ldots
}
\end{align*}

\subsubsection{Polymorphic Lists}
Polymorphic lists can be expressed using an abstract type member for
the element type ($\mi{Elem}$). We can instantiate a refinement of the
list package to manipulate lists with a particular element type. We
can choose to make the lists invariant or covariant in the element
type by fixing the lower bound of the $\mi{Elem}$ re-declaration to
the upper bound or to $\Bot$, respectively.

\begin{align*}
&\mlnew {\mi{genLists}} {\Top \mlrefine g {\Ldecl {\mi{ListPackage}} \Bot {\Top \mlrefine p {\\\displaybreak[3]
&\ \Ldecl {\mi{Elem}} \Bot \Top\\
&\ \Ldecl {\mi{ListOfElement}} {g.\mi{List} \refine z {\Ldecl {\mi{Elem}} {p.\mi{Elem}} {p.\mi{Elem}}}} {\\&\gap\gap\gap\gap g.\mi{List} \refine z {\Ldecl {\mi{Elem}} {p.\mi{Elem}} {p.\mi{Elem}}}}\\
&\ \Ldecl {\mi{List}} \Bot {\Top \mlrefine z {\\\displaybreak[3]
&\ \gap \ldecl {\mi{isEmpty}} {\mi{root}.\mi{Unit} \tfun \mi{root}.\mi{Boolean}}\\
&\ \gap \ldecl {\mi{head}} {\mi{root}.\mi{Unit} \tfun g.\mi{Elem}}\\
&\ \gap \ldecl {\mi{tail}} {\mi{root}.\mi{Unit} \tfun g.\mi{ListOfElem}}\\
&\gap}}\\
&\ \ldecl {\mi{nil}} {\mi{root}.\mi{Unit} \tfun g.\mi{ListOfElem}}\\
&\ \ldecl {\mi{cons}} {g.\mi{Elem} \tfun g.\mi{ListOfElem}}\\
&}}}}{
\mlnew {\mi{natLists}} {{\mi{genLists}.\mi{ListPackage}} \mlrefine p { \Ldecl {\mi{Elem}} {\mi{Nat}} {\mi{Nat}} }\mlldefs{\\\displaybreak[3]
&\ {\mi{nil}} = \ldots\\
&\ {\mi{cons}} = \ldots\\
&}}}{
\ldots
}
\end{align*}

\section{Counterexamples}\label{counterexs}

\subsection{Subtyping Transitivity and Preservation}\label{subpres}

Some subtyping transitivity is essential for soundness. Indeed, we show
how to construct a counterexample to preservation from any
counterexample to subtyping transitivity where the three involved
types $S, T, U$ are expressible within a realizable universe, though
the types themselves don't need to be realizable:

\begin{align*}
&\mlnew u \ldots {
\ \mlapp{\abs x \Top x}{
\ \ \mlapp{\abs f {S \tfun U} f}{
\ \ \ \mlapp{\abs f {S \tfun T} f}{
\ \ \ \ \mlapp{\abs f {S \tfun S} f}{
\ \ \  \ \ \abs x S x}}}}}
\end{align*}

The idea is to start with a function from $S \tfun S$ and cast it
successively to $S \tfun T$ then $S \tfun U$. To typecheck the
expression initially, we need to check $S \sub T$ and $T \sub
U$. After some reduction steps, the first few casts vanish, and the
reduced expression casts directly from $S \tfun S$ to $S \tfun U$, so
we need to check $S \sub U$. Thus, we need subtyping transitivity: $S
\sub T$ and $T \sub U$ implies $S \sub U$.

\subsection{Non-Expanding Types and Subtyping Transitivity}\label{nonexp}

The well-formedness rule $\textsc{tsel-wf$_2$}$ allow a type selection
$p.L$ to refer back to itself in its upper bound. This is useful for
expressing recursive class types and F-bounded abstract types.

Consider the simplest possible type that refers to itself: $p \typ T =
\Top \refine z {\Ldecl L \Bot z.L}$. Now, $p.L$ is well-formed but
non-expanding. Indeed, the only expansion rule that applies to $p.L$
is $\textsc{tsel-$\expand$}$, but it requires expanding the upper
bound... $p.L$! Thus, there is no finite derivation for the expansion
of $p.L$.

Non-expanding types are problematic for subtyping
transitivity. Consider: $p.L \sub \Top$ by \textsc{$\sub$-$\Top$} and
$\Top \sub \Top \refine z {}$ by \textsc{$\sub$-rfn}. By transitivity
on $\Top$, we expect $p.L \sub \Top \refine z {}$, but we cannot infer
this from the rules. The only rules that apply are \textsc{$\sub$-rfn}
and \textsc{tsel-$\sub$}. \textsc{$\sub$-rfn} gets stuck expanding
$p.L$. \textsc{tsel-$\sub$} gets stuck because the conclusion is also
a premise as $p \ni \Ldecl L \Bot p.L$.

For this counterexample, it seems enough to just add transitivity on
$\Top$ as a built-in rule. But this doesn't solve the general issue
that non-expanding types don't play well with subtyping. The problem
is deep, as it's possible to construct a realizable universe with
three non-trivial types that fail subtyping transitivity.

Consider an environment where $u$ is bound to:
\begin{align*}
\Top & \mlrefine u {\\
&\ \Ldecl {\mathit{Bad}} {\Bot} {u.\mathit{Bad}}\\
&\ \Ldecl {\mathit{Good}} {\Top \refine z {\Ldecl L \Bot \Top}} {\Top \refine z {\Ldecl L \Bot \Top}}\\
&\ \Ldecl {\mathit{Lower}} {u.\mathit{Bad} \tand u.\mathit{Good}} {u.\mathit{Good}}\\
&\ \Ldecl {\mathit{Upper}} {u.\mathit{Good}} {u.\mathit{Bad} \tor u.\mathit{Good}}\\
&\ \Ldecl X {u.\mathit{Lower}} {u.\mathit{Upper}}\\
}&
\end{align*}
Note that each lower bound is a subtype of its upper bound, so $u$ is
realizable. Hence, if we find a counterexample to subtyping
transitivity with types expressible within $u$, we can apply the trick
from section~\ref{subpres} to create a counterexample to preservation.

Indeed, here is such a counterexample to subtyping transitivity:
\begin{align*}
S &= u.\mathit{Bad} \tand u.\mathit{Good}\\
T &= u.\mathit{Lower}\\
U &= u.X \refine z {\Ldecl L \Bot \Top}
\end{align*}
We have $S <: T$ and $T <: U$, but we cannot derive $S <: U$ because
$S$ doesn't expand.

\subsection{Narrowing}\label{narrowing}

\subsubsection{Functions as Objects}\label{fun}

The original DOT calculus has both object and function types. It
doesn't have built-in methods, but they can be expressed as functional
labels. On the other hand, Scala doesn't have a built-in function
type. Instead, it has both methods and fields, and encodes functions
as objects with an apply method. Here, we show that the DOT model as
originally designed is problematic.

A concrete object can be a subtype of a function type without a
function ever being defined. Consider:
\begin{align*}
&\mlnew u {\Top \refine z {\Ldecl C {\Top \tfun \Top} {\Top \tfun \Top}} \ldefs{}} {
\mlnew f {u.C \ldefs{}} {
\ldots
}}
\end{align*}

Now, $f$ is a subtype of $\Top \tfun \Top$, but $\app f {(\abs x \Top
  x)}$ is stuck (and, rightfully, doesn't typecheck). But we can use
narrowing to create a counterexample to preservation: $\app {(\abs g
  {\Top \tfun \Top} {\app g (\abs x \Top x)})} f$.

\subsubsection{\texorpdfstring{\textsc{term-$\ni$}}{Term-Mem} Restriction}\label{term_mem}

There are two membership ($t \ni D$) rules: one for when the term $t$
is a path, and one for an arbitrary term $t$. For paths, we can
substitute the self-references in the declarations, but we cannot do
so for arbitrary terms as the resulting types wouldn't be well-formed
syntactically. Hence, the $\textsc{term-$\ni$}$ has the restriction
that self-occurrences are not allowed. Here is a counterexample related
to this restriction.

Let $X$ be a shorthand for the type:
\begin{align*}
\Top & \mlrefine z {\\
&\ \Ldecl {L_a} \Top \Top\\
&\ \ldecl l {z.L_a}\\
}&
\end{align*}

Let $Y$ be a shorthand for the type:
\begin{align*}
\Top & \mlrefine z {\\
&\ \ldecl l \Top\\
}&
\end{align*}

Now, consider the term
\begin{align*}
&\mlnew u {X \ldefs{ l = u }}{
(\app {(\abs y {\Top \tfun Y} {\app y u})} {(\abs d \Top {(\app {(\abs x X x)} u)})}).l
}
\end{align*}

The term type-checks because the term $t=(\app {(\abs y {\Top \tfun Y}
  {\app y u})} {(\abs d \Top {(\app {(\abs x X x)} u)})})$ has type
$Y$, so we can apply $\textsc{term-$\ni$}$ for $l$. However, the term
$t$ eventually steps to $(\app {(\abs x X x)} u)$ which has type $X$,
so we cannot apply $\textsc{term-$\ni$}$ for $l$ because of the
self-reference ($z.L_a$).

\subsubsection{Expansion Lost}\label{narrowing_exp}

Expansion is not preserved by narrowing. Here, we create two type
selections that are mutually recursive in their upper bounds after
narrowing: $z_0.C_2$ initially expands, but after narrowing, $z_0.C_2$
expands to what $z_0.A_2$ expands to, which expands to what $z_0.A_1$
expands to, which expands to what $z_0.A_2$ expands to, and thus we
have an infinite expansion. Thus, the last new expression initially
type-checks, but after narrowing, it doesn't because the precise
expansion needed by $\textsc{new}$ cannot be inferred.

\begin{align*}
&\mlnew {x_0} {\Top \mlrefine z { \Ldecl {A_1} \Bot {\Top \mlrefine z {\\
&\gap\Ldecl {A_2} \Bot \Top\\
&\gap\Ldecl {A_3} \Bot \Top\\
&\gap\Ldecl {C_2} \Bot {z.A_2}}}}\ldefs{}}{
\mlnew {x_1} {\Top \refine z {\Ldecl {C_1} \Bot {\Top \refine z {\Ldecl {A_1} \Bot {x_0.A_1}}}}\ldefs{}}}{
\mlnew {x_2} {{x_1.C_1} \refine z {\Ldecl {A_1} \Bot {{x_0.A_1} \refine z {\Ldecl {A_2} \Bot {z.A_3}}}}\ldefs{}}}{
\mlnew {x_3} {{x_1.C_1} \refine z {\Ldecl {A_1} \Bot {{x_0.A_1} \refine z {\Ldecl {A_3} \Bot {z.A_2}}}}\ldefs{}}}{
\mlapp {\abs x {x_1.C_1} {(\abs {z_0} {x.A_1 \tand x_3.A_1} {\\&\gap\gap\gap\new z {z_0.C_2} {\app {(\abs x \Top x)} z}})}} {\ x_2}}
\end{align*}

\subsubsection{Well-Formedness Lost}\label{narrowing_wf}

Even well-formedness is not preserved by narrowing. The trick is that
if the lower bound of a type selection is not $\Bot$, then the
bounds needs to be checked for well-formedness. Here, we create two
type selections that are mutually recursive in their bounds
after narrowing. $y.A$ is initially well-formed, but after narrowing,
it isn't because we run into an infinite derivation trying to prove
the well-formedness of its bounds.

\begin{align*}
&\mlnew v {\Top \refine z {\Ldecl L \Bot {\Top \refine z {\Ldecl A \Bot \Top, \Ldecl B {z.A} {z.A}}}} \ldefs{}}{
\mlapp {\abs x {\Top \refine z {\Ldecl L \Bot {\Top \refine z {\Ldecl A \Bot \Top, \Ldecl B \Bot \Top}}}} {\\&\gap
\mlnew z {\Top \refine z {\ldecl l {\Bot \tfun \Top}}\mlldefs{\\&\gap\gap l = \abs y {x.L \tand {\Top \refine z {\Ldecl A {z.B} {z.B}, \Ldecl B \Bot \Top}}} {\\&\gap\gap\gap\abs a {y.A} {\app {(\abs x \Top x)} a}}}}{
\ \app {(\abs x \Top x)} z
}}}{\ v}}
\end{align*}

\subsection{Path Equality}\label{patheq}

We need to be able to relate path-dependent types after reduction. The
original DOT calculus doesn't have any rules for dealing with
path-equality. Here is an example which motivates the need for
path-equality provisions.

\begin{align*}
&\mlnew b {\Top \mlrefine z {&&\Ldecl X \Top \Top&\\
&&&\ \ldecl l {z.X}&}\ldefs{l = b}}{
\mlnew a {\Top \mlrefine z {\ldecl i {\Top \mlrefine z {&&&\\
&&&\Ldecl X \Bot \Top\\
&&&\ldecl l {z.X}}}&}\ldefs{i = b}}}{
\app {(\abs x \Top x)} {(\app {(\abs x {a.i.X} x)} {a.i.l})}}
\end{align*}

$a.i.l$ reduces to $b.l$. $b.l$ has type $b.X$, so we need $b.X <:
a.i.X$. This cannot be established with the current rules: it is not
true in general, but true here because $a.i$ reduces to $b$. Hence,
the need for acknowledging path equality.

\section{Patches}\label{patches}

We have explored several patches to the calculus to deal with the
counterexamples presented above.

\subsection{Well-Formed and Expanding Types}\label{wfe}

We introduce a new judgment form for whether a type is well-formed
and expanding: $\Gamma \ts T \wfe$ if and only if $\Gamma \ts T \wf$
and $\exists \seq D$ such that $\Gamma \ts T \expand_z \seq D$. Then,
we replace all other uses of the $\wf$ judgment, including those
within the $\wf$ judgment inference rules, with uses of the $\wfe$
judgment.

We limit subtyping to $\wfe$ types. In fact, we make subtyping regular
with respect to $\wfe$: i.e., if $\Gamma \ts S <: T$, then $\Gamma \ts
S \wfe$ and $\Gamma \ts T \wfe$. Assuming a few lemmas, we are able to
formally prove that this modified subtyping judgment is
transitive. The most notable lemma we assume is the ``Galois
connection'' between subtyping and expansion: if $\Gamma \ts S \sub T
\spcomma S \expand_z \seq D_S \spcomma T \expand_z\seq D_T$, then
$\Gamma \envplus{z: S} \ts \seq{D_s \sub D_T}$.

\subsection{Functions as Sugar}\label{funsug}

We adopt Scala's model of treating functions as syntactic sugar for an
object with a special method. In order to do so, we introduce a new
kind of label for methods with one parameter: $m : S \tfun U$.

A difference in expressivity between this model and the original one
is that we now have to explicitly provide a return type of the method,
while the return type was inferred for functions. In practice, this is
cumbersome but not fundamentally limiting.

\subsection{Explicit Widening}\label{widening}

In the original DOT calculus, the \textsc{app} and \textsc{new} typing
rules have implicit relaxations. For instance, in \textsc{app}, the
argument type may be a subtype of the declared parameter type. In
order to deal with all the soundness problems due to narrowing, we
make widening an explicit operation and change those rules to be
strict by replacing those relaxed subtyping judgments with equality
judgments. Two types $S$ and $T$ are judged to be equal if $S <: T$
and $T <: S$.

Syntactically, we add a widening term: $\wid t T$, and extend values
with a case for widening: $\wid v T$. The typing rule for widening,
\textsc{wid}, is the only one admitting a subtyping relaxation:
$\Gamma \ts (\wid t T) \typ T$ if $\Gamma \ts t \typ T'$ and $\Gamma \ts T'
\sub T$.

The reduction rules become more complicated because the type
information in the widening needs to be propagated correctly. We will
motivate this informally with examples.

\begin{align*}
&\mlnew v {\Top \refine z {\Ldecl {L_a} \Bot \Top, \ldecl l {\Top \refine z {\Ldecl {L_a} \Bot \Top}}}\\
&\gap\gap\ldefs{l = \wid v {\Top \refine z {\Ldecl {L_a} \Bot \Top}}}}{
\app {(\abs x \Top x)} {(\wid v {\Top \refine z {\ldecl l \Top}}).l}
}
\end{align*}

The term $(\wid v {\Top \refine z {\ldecl l \Top}}).l$ first widens
$v$ so that the label has type $\Top$ instead of $\Top \refine z
{\Ldecl {L_a} \Bot \Top}$.

How should reduction proceed? We cannot just strip the widening and
then reduce, because then the strict function application would not
accept the reduced term. In short, we need to do some type
manipulations during reduction, by using the membership and expansion
judgments. This is a bit unfortunate, because it means that reduction
now needs to know about typing.

Next, we look at path equality provisions. These are even more
essential now in the presence of explicit widening. Consider this
example:

\begin{align*}
&\mlnew b {\Top \refine z {\Ldecl X \Top \Top, \ldecl l {z.X}} \ldefs{l = \wid b {b.X}}}{
\mlnew a {\Top \refine z {\ldecl i {\Top \refine z {\Ldecl X \Bot \Top, \ldecl l {z.X}}}}\\
&\gap\gap\ldefs{i = \wid b {\Top \refine z {\Ldecl X \Bot \Top, \ldecl l {z.X}}}}}}{
\wid {a.i.l} \Top
}
\end{align*}

$a.i.l$ reduces to $\wid b {\Top \refine z {\Ldecl X \Bot \Top, \ldecl
    l {z.X}}}$. Now, how can we continue? $b.l$ reduces to $b : b.X$
which has bounds $\Top..\Top$, but $(\wid b {\Top \refine z {\Ldecl X
    \Bot Top, \ldecl l {z.X}}}).l$ has bounds $\Bot..\Top$, so without
some provision for path equality, we cannot widen $b.l$ to $(\wid b
{\Top \refine z {\Ldecl X \Bot \Top, \ldecl l {z.X}}}).l$.

\subsection{Path Equality Provisions}

We add the path equality provisions to the subtyping rules.

Let's first ignore the extension of the calculus requiring explicit
widenings introduced in~\ref{widening}. Then, we need to add one
intuitive rule to the subtyping judgment: $\textsc{$\sub$-path}$. If
$p$ (path-)reduces to $q$, and $T \sub q.L$, then $T \sub p.L$. Path
reduction is a simplified form of reduction involving only
paths. However, this means that the subtyping judgment, and
indirectly, all the typing-related judgments, now need to carry the
store in addition to the context so that path reductions can be
calculated.

Now, let's see how path equality provisions and explicit widening can
fit together.

First, path reduction is not isomorphic to reduction anymore, since we
want to actually skip over widenings, as motivated by the last example
in~\ref{widening}.

In addition, we now also need a dual rule, $\textsc{path-$\sub$}$: if
$p$ (path-dually)-reduces to $q$, and $q.L \sub T$ then $p.L \sub
T$. This is because when we have a widening on an object on which a
method is called, we have to upcast the argument to the parameter type
expected by the original method. Here is a motivating example.

Let $T_c$ be a shorthand for the type:
\begin{align*}
\Top &\mlrefine z {\\
&\ \Ldecl A {\Top \refine z {\mdecl m \Bot \Top}} \Top\\
&\ \Ldecl B \Top \Top\\
&\ \mdecl m {z.A} \Top\\
}&
\end{align*}

Let $T$ be a shorthand for the type:
\begin{align*}
\Top &\mlrefine z {\\
&\ \Ldecl A {\Top \refine z {\mdecl m \Bot \Top}} \Top\\
&\ \Ldecl B \Top \Top\\
&\ \mdecl m {{z.A} \refine z {\Ldecl B \Top \Top}} \Top\\
}&
\end{align*}

Now, consider the term:
\begin{align*}
&\mlnew v {T_c \ldefs{m(x)=\wid x \Top}}{
(\wid v T).m(\wid v {((\wid v T).{A \refine z {\Ldecl B \Top \Top}})})
}
\end{align*}

When we evaluate the method invocation, we need to cast $\wid v
{((\wid v T).{A \refine z {\Ldecl B \Top \Top}})}$ to $v.A$, and for
this, we need the newly introduced $\textsc{path-$\sub$}$ rule.

Note that the path dual reduction can be a bit stricter with casts
than the path reduction. In any case, introducing this
$\textsc{path-$\sub$}$ rule into the subtyping judgment is
problematic: it is now possible to say $p.L \sub T$, even though $T$
can do more than what $p.L$ is defined to do. Here is an example,
where we construct an object, with $T = \Bot$. (The convolution in the
example is due to the requirement that concrete types be only
mentioned once.)

\begin{align*}
&\mlnew a {\Top \refine z {\Ldecl C \Bot {\Top \refine z {\Ldecl D \Bot {z.X}, \Ldecl X \Bot \Top}}}}{
\mlnew b {{a.C} \refine z {\Ldecl X \Bot \Bot}}}{
\mlnew c {a.C}}{
\mlnew d {(\wid b {a.C}).D}}{
\app {(\abs x \Bot {x.\mathit{foo}})} d
}
\end{align*}

Notice that $d$ has type $\Bot$ if you ignore the cast on $b$. This
example doesn't typecheck initially because $\textsc{path-$\sub$}$
only applies when objects are in the store, so the application is not
well-typed. But if we start preservation in a store which has $a$,
$b$, $c$ and $d$ then the application type-checks, because, through
$\textsc{path-$\sub$}$, we can find that the type of $d$ is a subtype
of $\Bot$. Now, of course, when we get to $d.\mathit{foo}$, reduction
fails.

So the preservation theorem as defined on a small-step semantics
(where we start with an arbitrary well-formed environment) fails when
we add the $\textsc{path-$\sub$}$ rule.

\section{Conclusion and Future Work}\label{conclusion}
This semester's work was instructive in pointing out the problematic
aspects of the original DOT calculus, and exploring some possible
fixes. However, I haven't been able to reach a revised calculus
without soundness hole. Furthermore, I believe that the revised
calculus with all the patches is not as elegant as the original
calculus. Going forward, I want to take a broader view by by studying
and incorporating ideas from other calculi which model dependent
types, and path-dependent types in particular.

\acks

I thank Adriaan Moors and Martin Odersky for sharing previous work,
fruitful discussions and guidance.

%\bibliographystyle{abbrvnat}
%\bibliography{bib}

\end{document}
