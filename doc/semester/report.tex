\documentclass[preprint]{sigplanconf}

\input{dot_macros}

    \usepackage[pdftex,
                hyperindex,
                plainpages=false,
                breaklinks,
                colorlinks,
                citecolor=black,
                filecolor=black,
                linkcolor=black,
                pagecolor=black,
                urlcolor=black]{hyperref}
    \usepackage[pdftex]{graphicx}
    \DeclareGraphicsExtensions{.jpg,.pdf}
    \pdfcatalog {
        /PageMode (/UseNone)
    }
    \usepackage{thumbpdf}
    \usepackage[pdftex]{color}

\begin{document}

\conferenceinfo{EDIC}{July 2012, EPFL.}
\copyrightyear{2012}
\copyrightdata{[to be supplied]}

\titlebanner{Dependent Object Types}                           % These are ignored unless
\preprintfooter{Spring 2012 Semester Project -- Nada Amin}     % 'preprint' option specified.

\title{Dependent Object Types}
\subtitle{Spring 2012 Semester Project}

\authorinfo{Nada Amin}
           {EPFL}
           {nada.amin@epfl.ch}

\maketitle

\begin{abstract}
In my semester project, I have studied a new proposed type-theoretic
foundation of Scala and languages like it: the Dependent Object Types
calculus (DOT). DOT models Scala's path-dependent types and abstract
type members, as well as its mixture of nominal and structural typing
through the use of refinement types. My ultimate goal was to prove DOT
sound, but instead, I found lots of counterexamples to soundness, and
have explored patches to the calculus.
\end{abstract}


\section{Introduction}

% TODO

\section{Counterexamples}

\subsection{Subtyping Transitivity and Preservation}\label{subpres}

Some subtyping transitivity is essential for soundness. Indeed, we show
how to construct a counterexample to preservation from any
counterexample to subtyping transitivity where the three involved
types $S, T, U$ are expressible within a realizable universe, though
the types themselves don't need to be realizable:

\begin{align*}
&\mlnew u \ldots {
\ \mlapp{\abs x \Top x}{
\ \ \mlapp{\abs f {S \tfun U} f}{
\ \ \ \mlapp{\abs f {S \tfun T} f}{
\ \ \ \ \mlapp{\abs f {S \tfun S} f}{
\ \ \  \ \ \abs x S x}}}}}
\end{align*}

The idea is to start with a function from $S \tfun S$ and cast it
successively to $S \tfun T$ then $S \tfun U$. To typecheck the
expression initially, we need to check $S \sub T$ and $T \sub
U$. After some reduction steps, the first few casts vanish, and the
reduced expression casts directly from $S \tfun S$ to $S \tfun U$, so
we need to check $S \sub U$. Thus, we need subtyping transitivity: $S
\sub T$ and $T \sub U$ implies $S \sub U$.

\subsection{Non-Expanding Types and Subtyping Transitivity}\label{nonexp}

The well-formedness rule $\textsc{tsel-wf$_2$}$ allow a type selection
$p.L$ to refer back to itself in its upper bound. This is useful for
expressing recursive class types and F-bounded abstract types.

Consider the simplest possible type that refers to itself: $p \typ T =
\Top \refine z {\Ldecl L \Bot z.L}$. Now, $p.L$ is well-formed but
non-expanding. Indeed, the only expansion rule that applies to $p.L$
is $\textsc{tsel-$\expand$}$, but it requires expanding the upper
bound... $p.L$! Thus, there is no finite derivation for the expansion
of $p.L$.

Non-expanding types are problematic for subtyping
transitivity. Consider: $p.L \sub \Top$ by \textsc{$\sub$-$\Top$} and
$\Top \sub \Top \refine z {}$ by \textsc{$\sub$-rfn}. By transitivity
on $\Top$, we expect $p.L \sub \Top \refine z {}$, but we cannot infer
this from the rules. The only rules that apply are \textsc{$\sub$-rfn}
and \textsc{tsel-$\sub$}. \textsc{$\sub$-rfn} gets stuck expanding
$p.L$. \textsc{tsel-$\sub$} gets stuck because the conclusion is also
a premise as $p \ni \Ldecl L \Bot p.L$.

For this counterexample, it seems enough to just add transitivity on
$\Top$ as a built-in rule. But this doesn't solve the general issue
that non-expanding types don't play well with subtyping. The problem
is deep, as it's possible to construct a realizable universe with
three non-trivial types that fail subtyping transitivity.

Consider an environment where $u$ is bound to:
\begin{align*}
\Top & \mlrefine u {\\
&\ \Ldecl {\mathit{Bad}} {\Bot} {u.\mathit{Bad}}\\
&\ \Ldecl {\mathit{Good}} {\Top \refine z {\Ldecl L \Bot \Top}} {\Top \refine z {\Ldecl L \Bot \Top}}\\
&\ \Ldecl {\mathit{Lower}} {u.\mathit{Bad} \tand u.\mathit{Good}} {u.\mathit{Good}}\\
&\ \Ldecl {\mathit{Upper}} {u.\mathit{Good}} {u.\mathit{Bad} \tor u.\mathit{Good}}\\
&\ \Ldecl X {u.\mathit{Lower}} {u.\mathit{Upper}}\\
}&
\end{align*}
Note that each lower bound is a subtype of its upper bound, so $u$ is
realizable. Hence, if we find a counterexample to subtyping
transitivity with types expressible within $u$, we can apply the trick
from section~\ref{subpres} to create a counterexample to preservation.

Indeed, here is such a counterexample to subtyping transitivity:
\begin{align*}
S &= u.\mathit{Bad} \tand u.\mathit{Good}\\
T &= u.\mathit{Lower}\\
U &= u.X \refine z {\Ldecl L \Bot \Top}
\end{align*}
We have $S <: T$ and $T <: U$, but we cannot derive $S <: U$ because
$S$ doesn't expand.

\subsection{Narrowing}\label{narrowing}

\subsubsection{Functions as Objects}\label{fun}

The original DOT calculus has both object and function types. It
doesn't have built-in methods, but they can be expressed as functional
labels. On the other hand, Scala doesn't have a built-in function
type. Instead, it has both methods and fields, and encodes functions
as objects with an apply method. Here, we show that the DOT model as
originally designed is problematic.

A concrete object can be a subtype of a function type without a
function ever being defined. Consider:
\begin{align*}
&\mlnew u {\Top \refine z {\Ldecl C {\Top \tfun \Top} {\Top \tfun \Top}} \ldefs{}} {
\mlnew f {u.C \ldefs{}} {
\ldots
}}
\end{align*}

Now, $f$ is a subtype of $\Top \tfun \Top$, but $\app f {(\abs x \Top
  x)}$ is stuck (and, rightfully, doesn't typecheck). But we can use
narrowing to create a counterexample to preservation: $\app {(\abs g
  {\Top \tfun \Top} {g (\abs x \Top x)})} f$.

\subsubsection{\texorpdfstring{\textsc{term-$\ni$}}{Term-Mem} Restriction}\label{term_mem}

There are two membership ($t \ni D$) rules: one for when the term $t$
is a path, and one for an arbitrary term $t$. For paths, we can
substitute the self-references in the declarations, but we cannot do
so for arbitrary terms as the resulting types wouldn't be well-formed
syntactically. Hence, the $\textsc{term-$\ni$}$ has the restriction
that self-ocurrences are not allowed. Here is a counterexample related
to this restriction.

Let $X$ be a shorthand for the type:
\begin{align*}
\Top & \mlrefine z {\\
&\ \Ldecl {L_a} \Top \Top\\
&\ \ldecl l {z.L_a}\\
}&
\end{align*}

Let $Y$ be a shorthand for the type:
\begin{align*}
\Top & \mlrefine z {\\
&\ \ldecl l \Top\\
}&
\end{align*}

Now, consider the term
\begin{align*}
&\mlnew u {X \ldefs{ l = u }}{
(\app {(\abs y {\Top \tfun Y} {\app y u})} {(\abs d \Top {(\app {(\abs x X x)} u)})}).l
}
\end{align*}

The term type-checks because the term $t=(\app {(\abs y {\Top \tfun Y}
  {\app y u})} {(\abs d \Top {(\app {(\abs x X x)} u)})})$ has type
$Y$, so we can apply $\textsc{term-$\ni$}$ for $l$. However, the term
$t$ eventually steps to $(\app {(\abs x X x)} u)$ which has type $X$,
so we cannot apply $\textsc{term-$\ni$}$ for $l$ because of the
self-reference ($z.L_a$).

\subsubsection{Expansion Lost}\label{narrowing_exp}

Expansion is not preserved by narrowing. Here, we create two type
selections that are mutually recursive in their upper bounds after
narrowing: $z_0.C2$ initially expands, but after narrowing, $z_0.C_2$
expands to what $z_0.A_2$ expands to, which expands to what $z_0.A_1$
expands to, which expands to what $z_0.A_2$ expands to, and thus we
have an infinite expansion. Thus, the last new expression initially
type-checks, but after narrowing, it doesn't because the precise
expansion needed by $\textsc{new}$ cannot be inferred.

\begin{align*}
&\mlnew {x_0} {\Top \mlrefine z { \Ldecl {A_1} \Bot {\Top \mlrefine z {\\
&\gap\Ldecl {A_2} \Bot \Top\\
&\gap\Ldecl {A_3} \Bot \Top\\
&\gap\Ldecl {C_2} \Bot {z.A_2}}}}\ldefs{}}{
\mlnew {x_1} {\Top \refine z {\Ldecl {C_1} \Bot {\Top \refine z {\Ldecl {A_1} \Bot {x_0.A_1}}}}\ldefs{}}}{
\mlnew {x_2} {{x_1.C_1} \refine z {\Ldecl {A_1} \Bot {{x_0.A_1} \refine z {\Ldecl {A_2} \Bot {z.A_3}}}}\ldefs{}}}{
\mlnew {x_3} {{x_1.C_1} \refine z {\Ldecl {A_1} \Bot {{x_0.A_1} \refine z {\Ldecl {A_3} \Bot {z.A_2}}}}\ldefs{}}}{
\mlapp {\abs x {x_1.C_1} {(\abs {z_0} {x.A_1 \tand x_3.A_1} {\new z {z_0.C_2} {\app {(\abs x \Top x)} z}})}} {\ x_2}}
\end{align*}

\subsubsection{Well-Formedness Lost}\label{narrowing_wf}

Even well-formedness is not preserved by narrowing. The trick is that
if the lower bound of a type selection is not $\Bot$, then the upper
bound needs to be checked for well-formedness. Here, we create two
type selections that are mutually recursive in their upper bounds
after narrowing. $y.A$ is initially well-formed, but after narrowing,
it isn't because we run into an infinite derivation trying to prove
the well-formedness of its upper bound.

\begin{align*}
&\mlnew v {\Top \refine z {\Ldecl L \Bot {\Top \refine z {\Ldecl A \Bot \Top, \Ldecl B {z.A} {z.A}}}} \ldefs{}}{
\mlapp {\abs x {\Top \refine z {\Ldecl L \Bot {\Top \refine z {\Ldecl A \Bot \Top, \Ldecl B \Bot \Top}}}} {\\&\gap
\mlnew z {\Top \refine z {\ldecl l {\Bot \tfun \Top}}\mlldefs{\\&\gap\gap l = \abs y {x.L \tand {\Top \refine z {\Ldecl A {z.B} {z.B}, \Ldecl B \Bot \Top}}} {\\&\gap\gap\gap\abs a {y.A} {\app {(\abs x \Top x)} a}}}}{
\ \app {(\abs x \Top x)} z
}}}{\ v}}
\end{align*}

\subsection{Path Equality}\label{patheq}

We need to be able to relate path-dependent types after reduction. The
original DOT calculus doesn't have any rules for dealing with
path-equality. Here is an example which motivates the need for
path-equality provisions.

\begin{align*}
&\mlnew b {\Top \mlrefine z {&&\Ldecl X \Top \Top&\\
&&&\ \ldecl l {z.X}&}\ldefs{l = b}}{
\mlnew a {\Top \mlrefine z {\ldecl i {\Top \mlrefine z {&&&\\
&&&\Ldecl X \Bot \Top\\
&&&\ldecl l {z.X}}}&}\ldefs{i = b}}}{
\app {(\abs x \Top x)} {(\app {(\abs x {a.i.X} x)} {a.i.l})}}
\end{align*}

$a.i.l$ reduces to $b.l$. $b.l$ has type $b.X$, so we need $b.X <:
a.i.X$. This cannot be established with the current rules: it is not
true in general, but true here because $a.i$ reduces to $b$. Hence,
the need for acknowledging path equality.

\section{Patches}

We have explored several patches to the calculus to deal with the
counterexamples presented above.

\subsection{Well-Formed and Expanding Types}\label{wfe}

We introduce a new judgement form for whether a type is well-formed
and expanding: $\Gamma \ts T \wfe$ if and only if $\Gamma \ts T \wf$
and $\exists \seq D$ such that $\Gamma \ts T \expand_z \seq D$. Then,
we replace all other uses of the $\wf$ judgment, including those
within the $\wf$ judgment inference rules, with uses of the $\wfe$
judgment.

We limit subtyping to $\wfe$ types. In fact, we make subtyping regular
with respect to $\wfe$: i.e., if $\Gamma \ts S <: T$, then $\Gamma \ts
S \wfe$ and $\Gamma \ts T \wfe$. Assuming a few lemmas, we are able to
formally prove that this modified subtyping judgment is
transitive. The most notable lemma we assume is the ``Galois
connection'' between subtyping and expansion: if $\Gamma \ts S \sub T
\spcomma S \expand_z \seq D_S \spcomma T \expand_z\seq D_T$, then
$\Gamma \envplus{z: S} \ts \seq{D_s \sub D_T}$.

\subsection{Functions as Sugar}\label{funsug}

We adopt Scala's model of treating functions as syntactic sugar for an
object with a special method. In order to do so, we introduce a new
kind of label for methods with one parameter: $m : S \tfun U$.

A difference in expressivity between this model and the original one
is that we now have to explicitly provide a return type of the method,
while the return type was inferred for functions. In practice, this is
cumbersome but not fundamentally limiting.

\subsection{Explicit Widening}\label{widening}

In the original DOT calculus, the \textsc{app} and \textsc{new} typing
rules have implicit relaxations. For instance, in \textsc{app}, the
argument type may be a subtype of the declared parameter type. In
order to deal with all the soundness problems due to narrowing, we
make widening an explicit operation and change those rules to be
strict by replacing those relaxed subtyping judgments with equality
judgments. Two types $S$ and $T$ are judged to be equal if $S <: T$
and $T <: S$.

Syntactically, we add a widening term: $\wid t T$, and extend values
with a case for widening: $\wid v T$. The typing rule for widening,
\textsc{wid}, is the only one admitting a subtyping relaxation:
$\Gamma \ts (\wid t T) \typ T$ if $\Gamma \ts t : T'$ and $\Gamma \ts T'
\sub T$.

The reduction rules become more complicated because the type
information in the widening needs to be propagated correctly. We will
motivate this informally with examples.

\begin{align*}
&\mlnew v {\Top \refine z {\Ldecl {L_a} \Bot \Top, \ldecl l {\Top \refine z {\Ldecl {L_a} \Bot \Top}}}\\
&\gap\gap\ldefs{l = \wid v {\Top \refine z {\Ldecl {L_a} \Bot \Top}}}}{
\app {(\abs x \Top x)} {(\wid v {\Top \refine z {\ldecl l \Top}}).l}
}
\end{align*}

The term $(\wid v {\Top \refine z {\ldecl l \Top}}).l$ first widens
$v$ so that the label has type $\Top$ instead of $\Top \refine z
{\Ldecl {L_a} \Bot \Top}$.

How should reduction proceed? We cannot just strip the widening and
then reduce, because then the strict function application would not
accept the reduced term. In short, we need to do some type
manipulations during reduction, by using the membership and expansion
judgments. This is a bit unfortunate, because it means that reduction
now needs to know about typing.

Next, we look at path equality provisions. These are even more
essential now in the presence of explicit widening. Consider this
example:

\begin{align*}
&\mlnew b {\Top \refine z {\Ldecl X \Top \Top, \ldecl l {z.X}} \ldefs{l = \wid b {b.X}}}{
\mlnew a {\Top \refine z {\ldecl i {\Top \refine z {\Ldecl X \Bot \Top, \ldecl l {z.X}}}}\\
&\gap\gap\ldefs{i = \wid b {\Top \refine z {\Ldecl X \Bot \Top, \ldecl l {z.X}}}}}}{
\wid {a.i.l} \Top
}
\end{align*}

$a.i.l$ reduces to $\wid b {\Top \refine z {\Ldecl X \Bot \Top, \ldecl
    l {z.X}}}$. Now, how can we continue? $b.l$ reduces to $b : b.X$
which has bounds $\Top..\Top$, but $(\wid b {\Top \refine z {\Ldecl X
    \Bot Top, \ldecl l {z.X}}}).l$ has bounds $\Bot..\Top$, so without
some provision for path equality, we cannot widen $b.l$ to $(\wid b
{\Top \refine z {\Ldecl X \Bot \Top, \ldecl l {z.X}}}).l$.

\subsection{Path Equality Provisions}

We add the path equality provisions to the subtyping rules.

Let's first ignore the extension of the calculus requiring explicit
widenings introduced in~\ref{widening}. Then, we need to add one
intuitive rule to the subtyping judgment: $\textsc{$\sub$-path}$. If
$p$ (path-)reduces to $q$, and $T \sub q.L$, then $T \sub p.L$. Path
reduction is a simplified form of reduction involving only
paths. However, this means that the subtyping judgment, and
indirectly, all the typing-related judgments, now need to carry the
store in addition to the context so that path reductions can be
calculated.

Now, let's see how path equality provisions and explicit widening can
fit together.

First, path reduction is not isomorphic to reduction anymore, since we
actually want to actually skip over widenings, as motivated by the
last example in~\ref{widening}.

In addition, we now also need a dual rule, $\textsc{path-$\sub$}$: if
$p$ (path-dually)-reduces to $q$, and $q.L \sub T$ then $p.L \sub
T$. This is because when we have a widening on an object on which a
method is called, we have to upcast the argument to the parameter type
expected by the original method. Here is a motivating example.

Let $T_c$ be a shorthand for the type:
\begin{align*}
\Top &\mlrefine z {\\
&\ \Ldecl A {\Top \refine z {\mdecl m \Bot \Top}} \Top\\
&\ \Ldecl B \Top \Top\\
&\ \mdecl m {z.A} \Top\\
}&
\end{align*}

Let $T$ be a shorthand for the type:
\begin{align*}
\Top &\mlrefine z {\\
&\ \Ldecl A {\Top \refine z {\mdecl m \Bot \Top}} \Top\\
&\ \Ldecl B \Top \Top\\
&\ \mdecl m {\Top \refine z {\Ldecl B \Top \Top}} \Top\\
}&
\end{align*}

Now, consider the term:
\begin{align*}
&\mlnew v {Tc \ldefs{m(x)=\wid x \Top}}{
(\wid v T).m(\wid v {(\wid v {A \refine z {\Ldecl B \Top \Top}})})
}
\end{align*}

When we evaluate the method invocation, we need to cast $\wid v {(\wid
  v {A \refine z {\Ldecl B \Top \Top}})}$ to $v.A$, and for this, we
need the newly introduced $\textsc{path-$\sub$}$ rule.

Note that the path dual reduction can be a bit stricter with casts
than the path reduction. In any case, introducing this
$\textsc{path-$\sub$}$ rule into the subtyping judgment is
problematic: it is now possible to say $p.L \sub T$, even though $T$
can do more than what $p.L$ is defined to do. Here is an example,
where we construct an object, with $T = \Bot$. (The convolution in the
example is due to the requirement that concrete types be only
mentioned once.)

\begin{align*}
&\mlnew a {\Top \refine z {\Ldecl C \Bot {\Top \refine z {\Ldecl D \Bot {z.X}, \Ldecl X \Bot \Top}}}}{
\mlnew b {{a.C} \refine z {\Ldecl X \Bot \Bot}}}{
\mlnew c {a.C}}{
\mlnew d {(\wid b {a.C}).D}}{
\app {(\abs x \Bot {x.\mathit{foo}})} d
}
\end{align*}

Notice that $d$ has type $\Bot$ if you ginore the cast on $b$. This
example doesn't typecheck initially because $\textsc{path-$\sub$}$
only applies when objects are in the store, so the application is not
well-typed. But if we start preservation in a store which has $a$,
$b$, $c$ and $d$ then the application type-checks, because, through
$\textsc{path-$\sub$}$, we can find that the type of $d$ is a subtype
of $\Bot$. Now, of course, when we get to $d.\mathit{foo}$, reduction
fails.

So the preservation theorem as defined on a small-step semantics
(where we start with an arbitrary well-formed environment) fails when
we add the $\textsc{path-$\sub$}$ rule.

\section{Conclucion and Future Work}

\acks

I thank Adriaan Moors and Martin Odersky for sharing previous work,
fruitful discussions and guidance.

%\bibliographystyle{abbrvnat}
%\bibliography{bib}

\end{document}
